\subsection{Hadoop Framework}
Das Apache Hadoop Framework ist ein, in Java geschriebenes, freies Framework für verteilt arbeitende Software. Es ist eine konkrete Implementierung des $MapReduce$-Algorithmus. Mit Hadoop sind intensive Berechnungsaufgaben über große Datenmengen im Petabyte-Bereich auf Clustern möglich. Es können herkömmliche Heimcomputer verwendet und als Cluster eingerichtet werden. Um die Funktionalität bereitzustellen nutzt Hadoop einerseits das eigens dafür entwickelte Dateisystem Hadoop Distributed File System und andererseits den $MapReduce$-Algorithmus. (vgl. \cite{wik16})\\ Betrieben werden kann Hadoop auf den geläufigen Unix/Linux Distributionen. Unter Windows läuft Hadoop hingegen nur mit Cygwin. Anwendungen die für oder auf Hadoop basieren können in den verschiedensten Programmiersprachen entwickelt werden. Darunter sind beispielsweise Java, Python und C++ um nur einen kleinen Teil zu nennen. Hadoop selbst benötigt mindestens Java 1.6. Neben dem eigenen Dateisystem HDFS werden noch weitere andere Storagemöglichkeiten wie Amazon S3, CloudStore oder Kosmos unterstützt.

\paragraph{HBase}$\;$ \\
HBase bildet eine skalierbare Datenbank für sehr große Datenmengen innerhalb des Hadoop Framework. HBase wurde als eine Implementierung von $Google BigTable$ entwickelt. Der Gegensatz von $Google BigTable$ zu relationalen Datenbanken besteht darin, dass die Anzahl der Spalten nicht für eine gesamte Tabelle bestimmt wird. Bei $Google BigTable$ kann die Anzahl der Spalten je Zeile variieren. Außerdem wird jede Zelle innerhalb einer Tabelle mit einem eigenen Zeitstempel versehen und kann dadurch sehr einfach versioniert werden.

\paragraph{Hive}$\;$ \\
Hive ist eine auf SQL basierende Abfragesprache. Ursprünglich wurde Hive von Facebook Inc. entwickelt steht aber seit 2008 als Open-Source-Version verfügbar. Der Nutzer kann mit Hive Tabellen und Spalten definieren und einen $MapReduce$ Prozess starten, welcher diese Tabellen und Spalten dann nutzt. Mit HiveQL, so der Name der Abfragesprache, lassen sich Zusammenfassungen, Berichte und Analysen erzeugen. (vgl. \cite{bmc10})

\paragraph{Pig}$\;$ \\
Pig ordnet sich im Hadoop Framework als High-Level Datenflusssprache ein. Mit Pig lassen sich einfach $MapReduce$ Programme entwickeln die auf einem Hadoop System ausgeführt werden können. Pig charakterisiert sich durch folgende Eigenschaften:

\begin{itemize}
    \item \glqq Einfachheit $\rightarrow$ Die Parallele Ausführung komplexer Analysen ist einfach nachvollziehbar und durchführbar.
    \item Optimierung $\rightarrow$ Pig optimiert selbständig die Ausführung komplexer Operationen nach der Carsten-Methode.
    \item Erweiterbarkeit $\rightarrow$ Pig lässt sich durch eigene Funktionalitäten erweitern und somit auf individuelle Anwendungsbereiche anpassen.\grqq(frei übersetzt von \cite{fou15})
\end{itemize}
